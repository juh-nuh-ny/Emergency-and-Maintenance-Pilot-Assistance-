{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pdfplumber\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import numpy as np\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Text extraction from each pdf\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# 2. Load and extract all pdfs from a directory\n",
    "def load_all_pdfs(pdf_directory):\n",
    "    documents=[]\n",
    "    \n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            full_path = os.path.join(pdf_directory, filename)\n",
    "            print(f\"Processing {full_path}...\")\n",
    "            text = extract_text_from_pdf(full_path)\n",
    "            documents.append(text)\n",
    "            \n",
    "    return documents\n",
    "\n",
    "# 3. Chunk into retrievable sections\n",
    "def chunk_documents(documents, chunk_size=500, chunk_overlap=50):\n",
    "    #tunable but works fine eitherways\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks=[]\n",
    "    for doc in documents:\n",
    "        doc_chunks = text_splitter.split_text(doc)\n",
    "        chunks.extend(doc_chunks)\n",
    "    return chunks\n",
    "\n",
    "# 4. Chunk Caching\n",
    "def load_or_generate_chunks(pdf_directory, chunks_cache_file=\"chunks_cache.pkl\", chunk_size=500, chunk_overlap=50):\n",
    "    if os.path.exists(chunks_cache_file):\n",
    "        print(f\"Loading cached chunks from {chunks_cache_file}...\")\n",
    "        with open(chunks_cache_file, \"rb\") as f:\n",
    "            chunks = pickle.load(f)\n",
    "    else:\n",
    "        print(\"No cached chunks found. Processing PDFs to generate chunks...\")\n",
    "        documents = load_all_pdfs(pdf_directory)\n",
    "        chunks = chunk_documents(documents, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        print(f\"Caching {len(chunks)} chunks to {chunks_cache_file}...\")\n",
    "        with open(chunks_cache_file, \"wb\") as f:\n",
    "            pickle.dump(chunks, f)\n",
    "    return chunks\n",
    "\n",
    "# 5. Embeddings generation\n",
    "def generate_embeddings(text_list, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size=32):\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    \n",
    "    embeddings = model.encode(text_list, batch_size=batch_size, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "# 6. Loading cache embeddings for saving time\n",
    "def load_or_generate_embeddings(chunks, cache_file=\"embeddings_cache.pkl\", model_name=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size=32):\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"rb\") as f:\n",
    "            embeddings = pickle.load(f)\n",
    "            \n",
    "        if embeddings.shape[0] != len(chunks):\n",
    "            print(\"Mismatch between cached embeddings and current chunk count. Regenerating embeddings.\")\n",
    "            embeddings = generate_embeddings(chunks, model_name=model_name, batch_size = batch_size)\n",
    "            with open (cache_file, \"wb\") as f:\n",
    "                pickle.dump(embeddings, f)\n",
    "    else:\n",
    "        print(\"No cached embeddings found, generating new ones...\")\n",
    "        embeddings = generate_embeddings(chunks, model_name = model_name, batch_size = batch_size)\n",
    "        print(f\"Caching embeddings to {cache_file}\")\n",
    "        with open(cache_file, \"wb\") as f:\n",
    "            pickle.dump(embeddings, f)\n",
    "    \n",
    "    return embeddings\n",
    "        \n",
    "# 7. FAISS index build for similarity search\n",
    "def build_faiss_index(embeddings):\n",
    "    if torch.is_tensor(embeddings):\n",
    "        embeddings_np = embeddings.cpu().numpy()\n",
    "    else:\n",
    "        embeddings_np = np.array(embeddings)\n",
    "        \n",
    "    dim = embeddings_np.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings_np)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading or generating chunks\n",
      "No cached chunks found. Processing PDFs to generate chunks...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/airlines-erp-checklist.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/Fox-Rothschild-Emergency-Response-Handbook-Jan-2020.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/Accident-IncidentPreparedness.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/78297d73-7754-426a-9294-0b70beefae74.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/737-800 Quick Reference Handbook (QRH).pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/19_afh_ch18.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/aviation-emergency-response-guidebook-2021.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/cc3.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/ndem_vpn_user_manual.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/00_afh_full.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/compilation-erp-4.0.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/AS-AMM-01-000_I1_R1_20180202.pdf...\n",
      "Processing /Users/jananinareshkumar/Desktop/rag/fly/Manual of Air Traffic Services, Part-1 Edition 6.2.pdf...\n",
      "Caching 13383 chunks to chunks_cache.pkl...\n",
      "13383 chunks loaded.\n",
      "Embedding Generation\n",
      "FAISS Index Setup\n",
      "FAISS Index contains 13383 vectors.\n",
      "Using device: mps\n",
      "Top 5 matches [[5114 9239 5115 9240 5121]]\n",
      "\n",
      "Chunk index 5114 with L2 distance 0.5580788850784302:\n",
      "manufacturer’s recommended procedures for a particular make and model airplane, the manufacturer’s recommended procedures take\n",
      "precedence.\n",
      "Emergency Landings\n",
      "This section contains information on emergency landing techniques in small fixed-wing airplanes. The guidelines that are presented\n",
      "apply to the more adverse terrain conditions for which no practical training is possible. The objective is to instill in the pilot the\n",
      "================================================================================\n",
      "\n",
      "Chunk index 9239 with L2 distance 0.5648911595344543:\n",
      "precedence.\n",
      "Emergency Landings\n",
      "This section contains information on emergency landing techniques in small fixed-wing airplanes. The guidelines that are presented\n",
      "apply to the more adverse terrain conditions for which no practical training is possible. The objective is to instill in the pilot the\n",
      "knowledge that almost any terrain can be considered “suitable” for a survivable crash landing if the pilot knows how to use the\n",
      "airplane structure for self-protection and the protection of passengers.\n",
      "================================================================================\n",
      "\n",
      "Chunk index 5115 with L2 distance 0.5840661525726318:\n",
      "knowledge that almost any terrain can be considered “suitable” for a survivable crash landing if the pilot knows how to use the\n",
      "airplane structure for self-protection and the protection of passengers.\n",
      "Types of Emergency Landings\n",
      "The different types of emergency landings are defined as follows:\n",
      "⦁ Forced landing—an immediate landing, on or off an airport, necessitated by the inability to continue further\n",
      "flight. A typical example of which is an airplane forced down by engine failure.\n",
      "================================================================================\n",
      "\n",
      "Chunk index 9240 with L2 distance 0.6294994950294495:\n",
      "Types of Emergency Landings\n",
      "The different types of emergency landings are defined as follows:\n",
      "⦁ Forced landing—an immediate landing, on or off an airport, necessitated by the inability to continue further\n",
      "flight. A typical example of which is an airplane forced down by engine failure.\n",
      "⦁ Precautionary landing—a premeditated landing, on or off an airport, when further flight is possible but\n",
      "================================================================================\n",
      "\n",
      "Chunk index 5121 with L2 distance 0.642363429069519:\n",
      "developed through the years. The success of an emergency landing is as much a matter of the mind as of\n",
      "skills.\n",
      "18-1\n",
      "⦁ Desire to save the airplane—the pilot who has been conditioned during training to expect to find a relatively\n",
      "safe landing area, whenever the flight instructor closed the throttle for a simulated forced landing, may\n",
      "ignore all basic rules of airmanship to avoid a touchdown in terrain where airplane damage is unavoidable.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pdf_directory = \"/Users/jananinareshkumar/Desktop/rag/fly\"\n",
    "    \n",
    "    # Load or generate chunks from the PDFs (using cached chunks if available)\n",
    "    print(\"Loading or generating chunks\")\n",
    "    chunks = load_or_generate_chunks(pdf_directory, chunks_cache_file=\"chunks_cache.pkl\", chunk_size=500, chunk_overlap=50)\n",
    "    print(f\"{len(chunks)} chunks loaded.\")\n",
    "    \n",
    "    # Generate or load cached embeddings for these chunks\n",
    "    print(\"Embedding Generation\")\n",
    "    embeddings = load_or_generate_embeddings(chunks, cache_file=\"embeddings_cache.pkl\")\n",
    "    \n",
    "    # Build the FAISS index\n",
    "    print(\"FAISS Index Setup\")\n",
    "    index = build_faiss_index(embeddings)\n",
    "    print(f\"FAISS Index contains {index.ntotal} vectors.\")\n",
    "    \n",
    "    # Query the index with a sample query\n",
    "    query_text = \"Emergency landing\"\n",
    "    query_embedding = generate_embeddings([query_text])\n",
    "    \n",
    "    # Convert the query embedding to a NumPy array for FAISS\n",
    "    if torch.is_tensor(query_embedding):\n",
    "        query_np = query_embedding.cpu().numpy()\n",
    "    else:\n",
    "        query_np = np.array(query_embedding)\n",
    "    \n",
    "    k = 5  # Number of nearest neighbors to retrieve\n",
    "    distances, indices = index.search(query_np, k)\n",
    "    print(\"Top 5 matches\", indices)\n",
    "    \n",
    "    # Optionally, print the text for each retrieved chunk\n",
    "    for distance, idx in zip(distances[0], indices[0]):\n",
    "        print(f\"\\nChunk index {idx} with L2 distance {distance}:\")\n",
    "        print(chunks[idx])\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_oneLastTime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
